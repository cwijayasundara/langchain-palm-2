{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Install the req. Python packages"
      ],
      "metadata": {
        "id": "4i5O6XThpN4Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zaxVtyvnZgMg"
      },
      "outputs": [],
      "source": [
        "! pip install -qU google-cloud-aiplatform langchain chromadb pypdf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restart the Runtime for Vertex AI"
      ],
      "metadata": {
        "id": "EG5lgNB1pUxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmjaTK-CbuDO",
        "outputId": "89baec44-ff66-4a99-c42b-5b4ab5b8b0f6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Authenticate the Colab notebook"
      ],
      "metadata": {
        "id": "PzTl1gMNpfmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "-hMg849LcLXx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"xxxxxx\"\n",
        "REGION = \"us-central1\"\n",
        "import vertexai\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)"
      ],
      "metadata": {
        "id": "4Jz36U2icOzA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ingest the GOOG's 2023 Q1 Results .pdf\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "url = \"https://abc.xyz/investor/static/pdf/2023Q1_alphabet_earnings_release.pdf?cache=0924ccf\"\n",
        "loader = PyPDFLoader(url)\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "6jqIQPThddyX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"# of words in the document = {len(documents[0].page_content)}\")"
      ],
      "metadata": {
        "id": "Elqmg1iPrcG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vertex AI\n",
        "from google.cloud import aiplatform\n",
        "from langchain.embeddings import VertexAIEmbeddings\n",
        "from langchain.llms import VertexAI\n",
        "from langchain.schema import HumanMessage, SystemMessage"
      ],
      "metadata": {
        "id": "0bEEevIKkN1Z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LLM model\n",
        "llm = VertexAI(\n",
        "    model_name=\"text-bison@001\",\n",
        "    max_output_tokens=256,\n",
        "    temperature=0.1,\n",
        "    top_p=0.8,\n",
        "    top_k=40,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "# Embedding\n",
        "embeddings = VertexAIEmbeddings(model_name=\"textembedding-gecko@001\")"
      ],
      "metadata": {
        "id": "DrzowbVMj_60"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summerise the 2023 Q1 file "
      ],
      "metadata": {
        "id": "s1-OdzS3mD8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=50)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "# There is a lot of complexity hidden in this one line.\n",
        "chain = load_summarize_chain(llm, chain_type=\"map_reduce\", verbose=True)\n",
        "chain.run(texts)"
      ],
      "metadata": {
        "id": "KKhLIq2LjCWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the document into chunks"
      ],
      "metadata": {
        "id": "l2VToHz6mcao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split the documents into chunks\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(documents)\n",
        "print(f\"# of documents = {len(docs)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MTY1MD6jCVw",
        "outputId": "5f412efa-14f5-4f87-dccd-45b35ac1c709"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of documents = 23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the documents in the Chroma Vector DB as embeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "db = Chroma.from_documents(docs, embeddings)"
      ],
      "metadata": {
        "id": "FC7RKpNvjCQy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Expose index to the retriever\n",
        "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2})"
      ],
      "metadata": {
        "id": "n7XdoSx5jCN6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create chain to answer questions\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# Uses Vertex PaLM Text API for LLM to synthesize results from the search index.\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True\n",
        ")"
      ],
      "metadata": {
        "id": "e3dRJEARjCLE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What was Alphabet's consolidated revenues for 2023?\"\n",
        "result = qa({\"query\": query})\n",
        "print(result)"
      ],
      "metadata": {
        "id": "SNSZqR5njCFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What was Alphabet's operating income for 2023?\"\n",
        "result = qa({\"query\": query})\n",
        "print(result)"
      ],
      "metadata": {
        "id": "wnt1f7-ouwLs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What were the charges related to reductions in workforce and office space?\"\n",
        "result = qa({\"query\": query})\n",
        "print(result)"
      ],
      "metadata": {
        "id": "4k7ceonJxbYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I am facing issues when trying to process much larger files:\n",
        "\n",
        "ResourceExhausted: 429 Quota exceeded for aiplatform.googleapis.com/online_prediction_requests_per_base_model with base model: textembedding-gecko. Please submit a quota increase request."
      ],
      "metadata": {
        "id": "HXCq5ahdy0nx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load GOOG's 10-K file which is a much larger file\n",
        "url = \"https://abc.xyz/investor/static/pdf/20230426_alphabet_10Q.pdf?cache=252acfb\"\n",
        "loader = PyPDFLoader(url)\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "AjgaYeIWy69B"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split the documents into chunks\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(documents)\n",
        "print(f\"# of documents = {len(docs)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdSqXrfv0O4q",
        "outputId": "ddae5f07-efc1-46af-a00f-8ebaf7409d14"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of documents = 112\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the documents in the Chroma Vector DB as embeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "db = Chroma.from_documents(docs, embeddings)"
      ],
      "metadata": {
        "id": "R5YGgQWy0XBg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}