{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDRJsEKmTI7g"
      },
      "outputs": [],
      "source": [
        "! pip install -qU google-cloud-aiplatform langchain chromadb pypdf transformers gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restart the CoLab Runtime"
      ],
      "metadata": {
        "id": "3T8U_-nxTbTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import IPython\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8ygXk_fTXOz",
        "outputId": "a0af5a0b-f059-4215-b364-a4e2358ad196"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "XI1GFENJTex7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import vertexai\n",
        "from google.cloud import aiplatform\n",
        "from langchain.llms import VertexAI\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import VertexAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "YLZ0zgbLTxmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"ibm-keras\"\n",
        "REGION = \"us-central1\"\n",
        "import vertexai\n",
        "vertexai.init(project=PROJECT_ID, location=REGION)\n",
        "\n",
        "llm = VertexAI(\n",
        "    model_name=\"text-bison@001\",\n",
        "    max_output_tokens=256,\n",
        "    temperature=0.1,\n",
        "    top_p=0.8,\n",
        "    top_k=40,\n",
        "    verbose=True,\n",
        ")\n",
        "# Embedding\n",
        "embeddings = VertexAIEmbeddings(model_name=\"textembedding-gecko@001\")"
      ],
      "metadata": {
        "id": "R12KGabfT7TE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This method violates the SRP!!"
      ],
      "metadata": {
        "id": "DDpLwpezk238"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_sec_file_to_vector_db(fileUrl, query):\n",
        "  url = fileUrl\n",
        "  loader = PyPDFLoader(url)\n",
        "  documents = loader.load()\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=0)\n",
        "  docs = text_splitter.split_documents(documents)\n",
        "  print(f\"# of documents = {len(docs)}\")\n",
        "  db = Chroma.from_documents(docs, embeddings)\n",
        "  retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 2})\n",
        "  # Uses Vertex PaLM Text API for LLM to synthesize results from the search index.\n",
        "  qa = RetrievalQA.from_chain_type(\n",
        "      llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True\n",
        "  )\n",
        "  result = qa({\"query\": query})\n",
        "  return result"
      ],
      "metadata": {
        "id": "k_HYXIQlUc-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def upload_and_chat_pdf(file_url, query):\n",
        "    return upload_sec_file_to_vector_db(file_url, query)\n",
        "\n",
        "sec_file_chat_app = gr.Interface(\n",
        "    fn=upload_and_chat_pdf,\n",
        "    inputs=[gr.Textbox(lines=3, placeholder=\"Please Enter the URL of the SEC Filling Here !\"),\n",
        "            gr.Textbox(lines=1, placeholder=\"Please Enter Your SEC File Query Here !\")],\n",
        "    outputs=\"text\",\n",
        ")\n",
        "sec_file_chat_app.launch(debug=True)"
      ],
      "metadata": {
        "id": "FMWLBSwjUJwo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}